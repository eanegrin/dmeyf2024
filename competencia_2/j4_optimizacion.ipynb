{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Vd-Rfyik62j"
   },
   "source": [
    "\n",
    "Modelo elegido para la competencia 01\n",
    "\n",
    "Si hay tiempo ver si se puede reemplazar pandas por polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Cj-rL6xHlA2u"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8jGKjoN1lRho"
   },
   "outputs": [],
   "source": [
    "# base_path = '/content/drive/MyDrive/DMEyF/2024/'\n",
    "base_path = 'C:/Eugenio/Maestria/DMEyF/'\n",
    "\n",
    "dataset_path = base_path + 'datasets/'\n",
    "modelos_path = base_path + 'modelos/'\n",
    "db_path = base_path + 'db/'\n",
    "dataset_file = 'datasets_competencia_02_fe_v01.parquet'\n",
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "# agregue sus semillas\n",
    "semillas = [122219, 109279, 400391, 401537, 999961]\n",
    "\n",
    "data = pl.read_parquet(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AlYeDIBQP3-s"
   },
   "outputs": [],
   "source": [
    "# Asignamos pesos a las clases\n",
    "\n",
    "data = data.with_columns(\n",
    "    pl.lit(1.0).alias(\"clase_peso\")\n",
    ")\n",
    "\n",
    "data = data.with_columns(\n",
    "    pl.when(pl.col(\"clase_ternaria\") == \"BAJA+2\").then(1.00002)\n",
    "    .when(pl.col(\"clase_ternaria\") == \"BAJA+1\").then(1.00001)\n",
    "    .otherwise(pl.col(\"clase_peso\"))\n",
    "    .alias(\"clase_peso\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzLIRVs850-I"
   },
   "source": [
    "Sumaremos la clase **BAJA+1**, que es estructuralmente muy similar a **BAJA+2**, para aumentar los casos positivos. Luego, compararemos los resultados obtenidos con los de la clase con la que hemos estado trabajando hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KV1meQ5cZ_Sl"
   },
   "outputs": [],
   "source": [
    "data = data.with_columns([\n",
    "    pl.when(pl.col(\"clase_ternaria\") == \"BAJA+2\").then(1).otherwise(0).alias(\"clase_binaria1\"), # solo los baja+2\n",
    "    pl.when(pl.col(\"clase_ternaria\") == \"CONTINUA\").then(0).otherwise(1).alias(\"clase_binaria2\") # combinando ambos bajas\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[201901,\n",
       " 201902,\n",
       " 201903,\n",
       " 201904,\n",
       " 201905,\n",
       " 201906,\n",
       " 201907,\n",
       " 201908,\n",
       " 201909,\n",
       " 201910,\n",
       " 201911,\n",
       " 201912,\n",
       " 202001,\n",
       " 202002,\n",
       " 202003,\n",
       " 202004,\n",
       " 202005,\n",
       " 202006,\n",
       " 202007,\n",
       " 202008,\n",
       " 202009,\n",
       " 202010,\n",
       " 202011,\n",
       " 202012,\n",
       " 202101,\n",
       " 202102,\n",
       " 202103,\n",
       " 202104,\n",
       " 202105,\n",
       " 202106,\n",
       " 202107,\n",
       " 202108]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"foto_mes\"].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meses_train = [202006,202007,202008,202009,202010,202011,202012,\n",
    "               202101,202102,202103,202104,202105,202106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.filter(pl.col(\"foto_mes\").is_in(meses_train))\n",
    "\n",
    "X_train = train_data.drop([\"clase_ternaria\", \"clase_peso\", \"clase_binaria1\", \"clase_binaria2\"])\n",
    "\n",
    "y_train_binaria1 = train_data[\"clase_binaria1\"]  # Solo BAJA+2\n",
    "y_train_binaria2 = train_data[\"clase_binaria2\"]  # junta a los 2 BAJA\n",
    "w_train = train_data[\"clase_peso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No imputo nulos porque el modelo los maneja\n",
    "\n",
    "# imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# Xif = imp_mean.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar la calidad del modelo, crearemos nuestra propia función de evaluación que calcule la ganancia. La razón de incluir los pesos es precisamente para poder implementar esta función de evaluación de manera adecuada. Al combinar las clases *BAJA+1* y *BAJA+2* en una sola, necesitamos una forma de diferenciarlas, y es aquí donde entra en juego el *weight*. Este parámetro nos permitirá distinguir entre ambas clases al momento de evaluarlas dentro del algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True\n",
    "\n",
    "# Parámetros del modelo.\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'gan_eval',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBM necesita su propio tipo de Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_data1 = lgb.Dataset(X_train, label=y_train_binaria1, weight=w_train)\n",
    "train_data2 = lgb.Dataset(X_train, label=y_train_binaria2, weight=w_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, compararemos las dos clases. Utilizaremos para medir la calidad de las clases (y de los parámetros), la función **cv** que viene *out-of-the-box*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results1 = lgb.cv(\n",
    "    params,\n",
    "    train_data1,\n",
    "    num_boost_round=150,\n",
    "    feval=lgb_gan_eval,\n",
    "    nfold=5,\n",
    "    seed=semillas[0]\n",
    ")\n",
    "\n",
    "cv_results2 = lgb.cv(\n",
    "    params,\n",
    "    train_data2,\n",
    "    num_boost_round=150,\n",
    "    feval=lgb_gan_eval,\n",
    "    nfold=5,\n",
    "    seed=semillas[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y vizualizamos los resultados de ambas ejecuciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ganancias = pd.DataFrame({\n",
    "    'binaria1': cv_results1['valid gan_eval-mean'],\n",
    "    'binaria2': cv_results2['valid gan_eval-mean'],\n",
    "    'Iteracion': range(1, len(cv_results1['valid gan_eval-mean']) + 1)\n",
    "})\n",
    "\n",
    "# Normalizamos la ganancias\n",
    "df_ganancias['binaria1'] = df_ganancias['binaria1']*5\n",
    "df_ganancias['binaria2'] = df_ganancias['binaria2']*5\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='Iteracion', y='binaria1', data=df_ganancias, label='binaria 1')\n",
    "sns.lineplot(x='Iteracion', y='binaria2', data=df_ganancias, label='binaria 2')\n",
    "plt.title('Comparación de las Ganancias de las 2 clases binarias')\n",
    "plt.xlabel('Iteración')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N96lUJOLDqLH"
   },
   "source": [
    "Se observa una ligera mejora al combinar las clases en modelos sencillos. Dado que cada pequeña mejora es importante, continuaremos utilizando esta estrategia.\n",
    "\n",
    "A continuación, procederemos a optimizar **LightGBM** utilizando la librería **Optuna**. Cabe destacar que las optimizaciones que realizaremos son básicas y están diseñadas para ejecutarse en pocos minutos. Será su responsabilidad ampliar tanto el rango de búsqueda como el tiempo de optimización para obtener un modelo más competitivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 100), # segun statquest esto deberia ir de 8 a 32\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.05), # mas bajo, más iteraciones necesita\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 1000),\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': semillas[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                              label=y_train_binaria2, # eligir la clase\n",
    "                              weight=w_train)\n",
    "    \n",
    "    # print(f\"Learning Rate: {learning_rate}, Type: {type(learning_rate)}\")\n",
    "    \n",
    "    # Use callbacks for early stopping\n",
    "    early_stopping_cb = lgb.early_stopping(stopping_rounds=50) # creo que en min_delta le tendria que pasar un parametro con la ganancia que considero irrelevante\n",
    "        \n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000, # modificar, subit y subir... y descomentar la línea inferior (ahora le puso 100 para mostrarnos, pero hay que ponerle un numero alto, 10.000, 200.000)\n",
    "        # early_stopping_rounds= int((50 + 5) / learning_rate), # (ale dijo que lo mas comun es que sea 1/learning rate)\n",
    "        # early_stopping_rounds = 50,\n",
    "        callbacks=[early_stopping_cb],\n",
    "        feval=lgb_gan_eval,\n",
    "        stratified=True,\n",
    "        nfold=5,\n",
    "        seed=semillas[0]\n",
    "    )\n",
    "    \n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 5 # funcion objetivo, en el proximo paso le digo si quiero maximizarla o minimizarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYMEnNFbkSoQ",
    "outputId": "15d768d4-9e25-4063-984b-d79c90ea91bc"
   },
   "outputs": [],
   "source": [
    "storage_name = \"sqlite:///\" + db_path + \"optimization_lgbm.db\"\n",
    "study_name = \"exp_301_lgbm_v03\" # UPDATE\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMrT22K0u9JF",
    "outputId": "75ee1c52-fb2c-4ad4-df1e-1d0852a3867e"
   },
   "outputs": [],
   "source": [
    "# study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ia2vN07FEasX"
   },
   "source": [
    "Analizamos los resultados as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "fH4ybQgYx7Xf",
    "outputId": "e2492e33-7da9-408e-bc68-ecc14c0fdf99"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "vOfm5DXAx8Rj",
    "outputId": "7ea05841-331e-48cb-fcb9-c36e97ab2051"
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0Z-r8QYEsNN"
   },
   "source": [
    "El **learning rate** es un parámetro que tiene que ir acompañado por más árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "0U6CfznSx-gG",
    "outputId": "f3c4a028-2d47-4e6e-ba8b-2877fe9d843a"
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "XRqPgCD6yB_q",
    "outputId": "0adae389-2981-43ee-c939-212232dd4f31"
   },
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "wGHGdGcQ3m00",
    "outputId": "624ee6d0-a5f1-4b00-bac6-8f37de7e99a7"
   },
   "outputs": [],
   "source": [
    "plot_contour(study, params=['num_leaves','min_data_in_leaf'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjgD6raVE6am"
   },
   "source": [
    "Y finalmente tomamos el mejor modelo y lo entrenamos con la totalidad de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwyUriQksZAM",
    "outputId": "c4b54b3e-75b0-4076-8a31-7096bd94382b"
   },
   "outputs": [],
   "source": [
    "best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': study.best_trial.params['num_leaves'],\n",
    "    'learning_rate': study.best_trial.params['learning_rate'],\n",
    "    'min_data_in_leaf': study.best_trial.params['min_data_in_leaf'],\n",
    "    'feature_fraction': study.best_trial.params['feature_fraction'],\n",
    "    'bagging_fraction': study.best_trial.params['bagging_fraction'],\n",
    "    'seed': semillas[0],\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                          label=y_train_binaria2,\n",
    "                          weight=w_train)\n",
    "\n",
    "model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  num_boost_round=best_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOyqa5mbFySM"
   },
   "source": [
    "Observamos la variables más importantes para el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xUejb7eutd0i",
    "outputId": "bdcd9641-679e-4de5-d0f8-cffdfc3bf241"
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(model, figsize=(10, 20))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkTH9daXF5tp"
   },
   "source": [
    "Y si queremos tener las variables más importantes en forma de *Dataframe*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "l7ZObpkHtnUl",
    "outputId": "eb0fe3a2-9e41-4886-ebd7-257dd1cf9829"
   },
   "outputs": [],
   "source": [
    "importances = model.feature_importance()\n",
    "feature_names = X_train.columns.tolist()\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "importance_df[importance_df['importance'] > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwvqxqc_GB-C"
   },
   "source": [
    "Para guardar el modelo para poder utilizarlo más adelante, no es necesario guardarlo como *pickle*, la librería nos permite guardarlo en formato texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lWWxwHhs2gp"
   },
   "outputs": [],
   "source": [
    "model.save_model(modelos_path + 'lgb_v003.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto de corte optimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgm = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganancia = np.where(y_train_binaria1 == 1, ganancia_acierto, 0) - np.where(y_train_binaria1 == 0, costo_estimulo, 0) # uso la binaria 1 porque es la que solo considera a los BAJA+2\n",
    "\n",
    "idx = np.argsort(y_pred_lgm)[::-1]\n",
    "\n",
    "ganancia = ganancia[idx]\n",
    "y_pred_lgm = y_pred_lgm[idx]\n",
    "\n",
    "ganancia_cum = np.cumsum(ganancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piso_envios = 4000\n",
    "techo_envios = 20000\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_pred_lgm[piso_envios:techo_envios], ganancia_cum[piso_envios:techo_envios], label='Ganancia LGBM')\n",
    "plt.title('Curva de Ganancia')\n",
    "plt.xlabel('Predicción de probabilidad')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.axvline(x=0.025, color='g', linestyle='--', label='Punto de corte a 0.025')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vez de mirar el punto de corte, empezaremos a pensar en cuál es la cantidad máxima de clientes que se deben estimular. Si cambiamos a esto, veremos que el gráfico anterior se ve así"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piso_envios = 4000\n",
    "techo_envios = 20000\n",
    "\n",
    "ganancia_max = ganancia_cum.max()\n",
    "gan_max_idx = np.where(ganancia_cum == ganancia_max)[0][0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(piso_envios, len(ganancia_cum[piso_envios:techo_envios]) + piso_envios), ganancia_cum[piso_envios:techo_envios], label='Ganancia LGBM')\n",
    "plt.axvline(x=gan_max_idx, color='g', linestyle='--', label=f'Punto de corte a la ganancia máxima {gan_max_idx}')\n",
    "plt.axhline(y=ganancia_max, color='r', linestyle='--', label=f'Ganancia máxima {ganancia_max}')\n",
    "plt.title('Curva de Ganancia')\n",
    "plt.xlabel('Clientes')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entreno con marzo y estimo para abril porque eran los unicos 2 meses para los cuales tengo todas las varibales temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data['foto_mes'] == 202103]\n",
    "test_data = data[data['foto_mes'] == 202104]\n",
    "\n",
    "X_train = train_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_train_binaria1 = train_data['clase_binaria1']\n",
    "y_train_binaria2 = train_data['clase_binaria2']\n",
    "w_train = train_data['clase_peso']\n",
    "\n",
    "X_test = test_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_test_binaria1 = test_data['clase_binaria1']\n",
    "y_test_class = test_data['clase_ternaria']\n",
    "w_test = test_data['clase_peso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo solo con los datos de marzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': study.best_trial.params['num_leaves'],\n",
    "    'learning_rate': study.best_trial.params['learning_rate'],\n",
    "    'min_data_in_leaf': study.best_trial.params['min_data_in_leaf'],\n",
    "    'feature_fraction': study.best_trial.params['feature_fraction'],\n",
    "    'bagging_fraction': study.best_trial.params['bagging_fraction'],\n",
    "    'seed': semillas[0],\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train,\n",
    "                          label=y_train_binaria2,\n",
    "                          weight=w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  num_boost_round=best_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28TQpPlIGi6a"
   },
   "source": [
    "obtenemos la predicción de **Abril**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kL9dBAv4xWz2"
   },
   "outputs": [],
   "source": [
    "y_pred_lgm = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85csWJ6p5huj"
   },
   "outputs": [],
   "source": [
    "ganancia = np.where(y_test_binaria1 == 1, ganancia_acierto, 0) - np.where(y_test_binaria1 == 0, costo_estimulo, 0)\n",
    "\n",
    "idx = np.argsort(y_pred_lgm)[::-1]\n",
    "\n",
    "ganancia = ganancia[idx]\n",
    "y_pred_lgm = y_pred_lgm[idx]\n",
    "\n",
    "ganancia_cum = np.cumsum(ganancia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "yULvAtz964Ek",
    "outputId": "0abfbb79-2f4c-4a53-cc5e-7c6cc947e969"
   },
   "outputs": [],
   "source": [
    "piso_envios = 4000\n",
    "techo_envios = 20000\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_pred_lgm[piso_envios:techo_envios], ganancia_cum[piso_envios:techo_envios], label='Ganancia LGBM')\n",
    "plt.title('Curva de Ganancia')\n",
    "plt.xlabel('Predicción de probabilidad')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.axvline(x=0.025, color='g', linestyle='--', label='Punto de corte a 0.025')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "LgLC9YI15xr8",
    "outputId": "b403cf68-5cd1-40aa-8653-03cc3a73dcf0"
   },
   "outputs": [],
   "source": [
    "piso_envios = 4000\n",
    "techo_envios = 20000\n",
    "\n",
    "ganancia_max = ganancia_cum.max()\n",
    "gan_max_idx = np.where(ganancia_cum == ganancia_max)[0][0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(piso_envios, len(ganancia_cum[piso_envios:techo_envios]) + piso_envios), ganancia_cum[piso_envios:techo_envios], label='Ganancia LGBM')\n",
    "plt.axvline(x=gan_max_idx, color='g', linestyle='--', label=f'Punto de corte a la ganancia máxima {gan_max_idx}')\n",
    "plt.axhline(y=ganancia_max, color='r', linestyle='--', label=f'Ganancia máxima {ganancia_max}')\n",
    "plt.title('Curva de Ganancia')\n",
    "plt.xlabel('Clientes')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar prediccion para Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejores parametros que habian surgido de la optimizacion de Optuna\n",
    "\n",
    "best_iter = 381 # cantidad de arboles del mejor modelo\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': 57,\n",
    "    'learning_rate': 0.02430667011066182,\n",
    "    'min_data_in_leaf': 741,\n",
    "    'feature_fraction': 0.43258351876617523,\n",
    "    'bagging_fraction': 0.4885097776912656,\n",
    "    'seed': 122219,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# y cantidad optima de envios segun backtesting\n",
    "corte = 10669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data['foto_mes'].isin([202104])]\n",
    "future_data = data[data['foto_mes'] == 202106]\n",
    "\n",
    "X_train = train_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_train_binaria1 = train_data['clase_binaria1']\n",
    "y_train_binaria2 = train_data['clase_binaria2']\n",
    "w_train = train_data['clase_peso']\n",
    "\n",
    "X_test = future_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entreno el modelo con los datos de abril y los parametros optimos de Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train,\n",
    "                          label=y_train_binaria2,\n",
    "                          weight=w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  num_boost_round=best_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago la prediccion para junio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgm = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego la prediccion en el dataset de test\n",
    "X_test['pred_lgm'] = y_pred_lgm\n",
    "\n",
    "#  ordeno por probabilidad para marcar a quienes les vamos a enviar el estimulo\n",
    "idx = np.argsort(y_pred_lgm)[::-1]\n",
    "X_test.reset_index(drop=True, inplace=True) # reseteo el index para poder ordenar por idx, sino en index tenia por default el numero de fila del dataframe original \"data\"\n",
    "X_test = X_test.iloc[idx]\n",
    "\n",
    "# genero la columna con 1s para los que van a recibir el estimulo, 0 para todo el resto\n",
    "envios = np.zeros(len(X_test), dtype=int)\n",
    "envios[:corte] = 1\n",
    "X_test['Predicted'] = envios\n",
    "\n",
    "# otra forma seria:\n",
    "# X_test['Predicted'] = 0\n",
    "# X_test.loc[:gan_max_idx-1, 'Predicted'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero el archivo para kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = X_test[['numero_de_cliente', 'Predicted']]\n",
    "\n",
    "file_name = 'results_v03_01.csv'\n",
    "output_path = base_path + 'exp/KA2001/' + file_name\n",
    "\n",
    "# output.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando distintas semillas y puntos de corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a probar 20 puntos de corte para cada semilla (total 100 envios)\n",
    "\n",
    "semillas\n",
    "puntos_corte = np.linspace(9000, 13000, 20).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "\n",
    "# for semilla in semillas:\n",
    "    \n",
    "#     # entrenamos el modelo con la semilla\n",
    "#     params['seed'] = semilla\n",
    "#     model = lgb.train(params, train_data, num_boost_round=best_iter)\n",
    "    \n",
    "#     # predecimos para junio\n",
    "#     X_test = future_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1).copy()\n",
    "#     y_pred_lgm = model.predict(X_test)\n",
    "#     X_test['pred_lgm'] = y_pred_lgm\n",
    "    \n",
    "#     # ordeno de mayor probabilidad de baja a menor\n",
    "#     idx = np.argsort(y_pred_lgm)[::-1]\n",
    "#     X_test.reset_index(drop=True, inplace=True)\n",
    "#     X_test = X_test.iloc[idx]\n",
    "    \n",
    "#     for corte in puntos_corte:\n",
    "        \n",
    "#         envios = np.zeros(len(X_test), dtype=int)\n",
    "#         envios[:corte] = 1\n",
    "#         X_test['Predicted'] = envios\n",
    "        \n",
    "#         output = X_test[['numero_de_cliente', 'Predicted']]\n",
    "        \n",
    "#         counter += 1\n",
    "#         file_name = f'results_v03_{counter}.csv'\n",
    "#         output_path = base_path + 'exp/KA2001/' + file_name\n",
    "        \n",
    "#         output.to_csv(output_path, index=False)\n",
    "                \n",
    "#         print(f'{output_path} --- seed: {semilla}, corte: {corte}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subir a kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import time\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "competition = 'dm-ey-f-2024-primera'\n",
    "files_path = 'C:/Eugenio/Maestria/DMEyF/exp/KA2001/'\n",
    "modelo = 'v03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diccionario con la semilla y el corte de cada version\n",
    "combinations = {}\n",
    "counter = 1\n",
    "for semilla in semillas:\n",
    "    for corte in puntos_corte:\n",
    "        combinations[counter] = {'seed':semilla,'corte':int(corte)}\n",
    "        counter += 1\n",
    "\n",
    "# path de cada version        \n",
    "files = [f'{files_path}results_{modelo}_{i}.csv' for i in range(1,101)]\n",
    "\n",
    "# descripcion de cada edicion\n",
    "descriptions= [\n",
    "    f\"seed = {combinations[i]['seed']}, corte = {combinations[i]['corte']}\"\n",
    "    for i in range(1, len(combinations)+1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos = []\n",
    "scores = []\n",
    "descripciones = []\n",
    "\n",
    "for i in range(len(files)):\n",
    "\n",
    "    submitted = False\n",
    "    while submitted == False:\n",
    "        try:\n",
    "            # Submit the file\n",
    "            api.competition_submit(file_name=files[i],\n",
    "                                   message=descriptions[i],\n",
    "                                   competition=competition)\n",
    "        except Exception as e:\n",
    "            print(f'Error al subir {files[i]}: {e}')\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            submitted = True \n",
    "\n",
    "            # Esperamos un poco para que kaggle no tire error\n",
    "            time.sleep(10)\n",
    "\n",
    "            submissions = api.competition_submissions(competition, page_size=1) # traigo solo la ultima\n",
    "            ultima = submissions[0]\n",
    "            \n",
    "            archivo = ultima.fileName\n",
    "            public_score = ultima.publicScore\n",
    "            descripcion = ultima.description\n",
    "            \n",
    "            archivos.append(archivo)\n",
    "            scores.append(public_score)\n",
    "            descripciones.append(descripcion)\n",
    "            \n",
    "            print(f'{archivo} subido con exito, public score:{public_score}')\n",
    "            \n",
    "resultados = pd.DataFrame({\n",
    "    'Archivo': archivos,\n",
    "    'Public score': scores,\n",
    "    'Description':descripciones\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardo los resultados\n",
    "\n",
    "resultados = pd.DataFrame(\n",
    "    {'Archivo': {0: 'results_v03_1.csv',\n",
    "                1: 'results_v03_2.csv',\n",
    "                2: 'results_v03_3.csv',\n",
    "                3: 'results_v03_4.csv',\n",
    "                4: 'results_v03_5.csv',\n",
    "                5: 'results_v03_6.csv',\n",
    "                6: 'results_v03_7.csv',\n",
    "                7: 'results_v03_8.csv',\n",
    "                8: 'results_v03_9.csv',\n",
    "                9: 'results_v03_10.csv',\n",
    "                10: 'results_v03_11.csv',\n",
    "                11: 'results_v03_12.csv',\n",
    "                12: 'results_v03_13.csv',\n",
    "                13: 'results_v03_14.csv',\n",
    "                14: 'results_v03_15.csv',\n",
    "                15: 'results_v03_16.csv',\n",
    "                16: 'results_v03_17.csv',\n",
    "                17: 'results_v03_18.csv',\n",
    "                18: 'results_v03_19.csv',\n",
    "                19: 'results_v03_20.csv',\n",
    "                20: 'results_v03_21.csv',\n",
    "                21: 'results_v03_22.csv',\n",
    "                22: 'results_v03_23.csv',\n",
    "                23: 'results_v03_24.csv',\n",
    "                24: 'results_v03_25.csv',\n",
    "                25: 'results_v03_26.csv',\n",
    "                26: 'results_v03_27.csv',\n",
    "                27: 'results_v03_28.csv',\n",
    "                28: 'results_v03_29.csv',\n",
    "                29: 'results_v03_30.csv',\n",
    "                30: 'results_v03_31.csv',\n",
    "                31: 'results_v03_32.csv',\n",
    "                32: 'results_v03_33.csv',\n",
    "                33: 'results_v03_34.csv',\n",
    "                34: 'results_v03_35.csv',\n",
    "                35: 'results_v03_36.csv',\n",
    "                36: 'results_v03_37.csv',\n",
    "                37: 'results_v03_38.csv',\n",
    "                38: 'results_v03_39.csv',\n",
    "                39: 'results_v03_40.csv',\n",
    "                40: 'results_v03_41.csv',\n",
    "                41: 'results_v03_42.csv',\n",
    "                42: 'results_v03_43.csv',\n",
    "                43: 'results_v03_44.csv',\n",
    "                44: 'results_v03_45.csv',\n",
    "                45: 'results_v03_46.csv',\n",
    "                46: 'results_v03_47.csv',\n",
    "                47: 'results_v03_48.csv',\n",
    "                48: 'results_v03_49.csv',\n",
    "                49: 'results_v03_50.csv',\n",
    "                50: 'results_v03_51.csv',\n",
    "                51: 'results_v03_52.csv',\n",
    "                52: 'results_v03_53.csv',\n",
    "                53: 'results_v03_54.csv',\n",
    "                54: 'results_v03_55.csv',\n",
    "                55: 'results_v03_56.csv',\n",
    "                56: 'results_v03_57.csv',\n",
    "                57: 'results_v03_58.csv',\n",
    "                58: 'results_v03_59.csv',\n",
    "                59: 'results_v03_60.csv',\n",
    "                60: 'results_v03_61.csv',\n",
    "                61: 'results_v03_62.csv',\n",
    "                62: 'results_v03_63.csv',\n",
    "                63: 'results_v03_64.csv',\n",
    "                64: 'results_v03_65.csv',\n",
    "                65: 'results_v03_66.csv',\n",
    "                66: 'results_v03_67.csv',\n",
    "                67: 'results_v03_68.csv',\n",
    "                68: 'results_v03_69.csv',\n",
    "                69: 'results_v03_70.csv',\n",
    "                70: 'results_v03_71.csv',\n",
    "                71: 'results_v03_72.csv',\n",
    "                72: 'results_v03_73.csv',\n",
    "                73: 'results_v03_74.csv',\n",
    "                74: 'results_v03_75.csv',\n",
    "                75: 'results_v03_76.csv',\n",
    "                76: 'results_v03_77.csv',\n",
    "                77: 'results_v03_78.csv',\n",
    "                78: 'results_v03_79.csv',\n",
    "                79: 'results_v03_80.csv',\n",
    "                80: 'results_v03_81.csv',\n",
    "                81: 'results_v03_82.csv',\n",
    "                82: 'results_v03_83.csv',\n",
    "                83: 'results_v03_84.csv',\n",
    "                84: 'results_v03_85.csv',\n",
    "                85: 'results_v03_86.csv',\n",
    "                86: 'results_v03_87.csv',\n",
    "                87: 'results_v03_88.csv',\n",
    "                88: 'results_v03_89.csv',\n",
    "                89: 'results_v03_90.csv',\n",
    "                90: 'results_v03_91.csv',\n",
    "                91: 'results_v03_92.csv',\n",
    "                92: 'results_v03_93.csv',\n",
    "                93: 'results_v03_94.csv',\n",
    "                94: 'results_v03_95.csv',\n",
    "                95: 'results_v03_96.csv',\n",
    "                96: 'results_v03_97.csv',\n",
    "                97: 'results_v03_98.csv',\n",
    "                98: 'results_v03_99.csv',\n",
    "                99: 'results_v03_100.csv'},\n",
    " 'Public score': {0: '84.161',\n",
    "                  1: '83.671',\n",
    "                  2: '84.884',\n",
    "                  3: '86.331',\n",
    "                  4: '88.011',\n",
    "                  5: '89.364',\n",
    "                  6: '93.261',\n",
    "                  7: '95.594',\n",
    "                  8: '95.011',\n",
    "                  9: '93.914',\n",
    "                  10: '92.467',\n",
    "                  11: '92.864',\n",
    "                  12: '91.207',\n",
    "                  13: '89.877',\n",
    "                  14: '88.244',\n",
    "                  15: '88.477',\n",
    "                  16: '89.061',\n",
    "                  17: '88.687',\n",
    "                  18: '87.241',\n",
    "                  19: '89.621',\n",
    "                  20: '90.227',\n",
    "                  21: '95.267',\n",
    "                  22: '96.317',\n",
    "                  23: '96.784',\n",
    "                  24: '96.014',\n",
    "                  25: '97.390',\n",
    "                  26: '96.807',\n",
    "                  27: '97.274',\n",
    "                  28: '96.574',\n",
    "                  29: '96.294',\n",
    "                  30: '97.320',\n",
    "                  31: '96.900',\n",
    "                  32: '97.437',\n",
    "                  33: '96.014',\n",
    "                  34: '98.184',\n",
    "                  35: '97.717',\n",
    "                  36: '97.157',\n",
    "                  37: '96.340',\n",
    "                  38: '96.527',\n",
    "                  39: '97.647',\n",
    "                  40: '92.421',\n",
    "                  41: '90.857',\n",
    "                  42: '94.917',\n",
    "                  43: '93.704',\n",
    "                  44: '94.941',\n",
    "                  45: '93.541',\n",
    "                  46: '92.957',\n",
    "                  47: '92.141',\n",
    "                  48: '93.471',\n",
    "                  49: '94.591',\n",
    "                  50: '93.004',\n",
    "                    51: '93.214',\n",
    "                    52: '94.287',\n",
    "                    53: '93.657',\n",
    "                    54: '94.147',\n",
    "                    55: '93.587',\n",
    "                    56: '92.397',\n",
    "                    57: '92.047',\n",
    "                    58: '91.511',\n",
    "                    59: '90.087',\n",
    "                    60: '93.611',\n",
    "                    61: '92.094',\n",
    "                    62: '93.284',\n",
    "                    63: '92.701',\n",
    "                    64: '93.377',\n",
    "                    65: '94.684',\n",
    "                    66: '95.034',\n",
    "                    67: '95.431',\n",
    "                    68: '94.684',\n",
    "                    69: '96.807',\n",
    "                    70: '96.504',\n",
    "                    71: '96.737',\n",
    "                    72: '97.087',\n",
    "                    73: '96.224',\n",
    "                    74: '96.760',\n",
    "                    75: '96.224',\n",
    "                    76: '96.084',\n",
    "                    77: '96.434',\n",
    "                    78: '95.897',\n",
    "                    79: '95.407',\n",
    "                    80: '87.987',\n",
    "                    81: '89.527',\n",
    "                    82: '90.834',\n",
    "                    83: '92.351',\n",
    "                    84: '91.907',\n",
    "                    85: '92.351',\n",
    "                    86: '93.564',\n",
    "                    87: '94.264',\n",
    "                    88: '95.384',\n",
    "                    89: '95.197',\n",
    "                    90: '96.504',\n",
    "                    91: '98.674',\n",
    "                    92: '98.137',\n",
    "                    93: '96.457',\n",
    "                    94: '95.011',\n",
    "                    95: '94.147',\n",
    "                    96: '95.221',\n",
    "                    97: '94.707',\n",
    "                    98: '95.851',\n",
    "                    99: '95.337'},\n",
    " 'Description': {0: 'seed = 122219, corte = 9000',\n",
    "                1: 'seed = 122219, corte = 9210',\n",
    "                2: 'seed = 122219, corte = 9421',\n",
    "                3: 'seed = 122219, corte = 9631',\n",
    "                4: 'seed = 122219, corte = 9842',\n",
    "                5: 'seed = 122219, corte = 10052',\n",
    "                6: 'seed = 122219, corte = 10263',\n",
    "                7: 'seed = 122219, corte = 10473',\n",
    "                8: 'seed = 122219, corte = 10684',\n",
    "                9: 'seed = 122219, corte = 10894',\n",
    "                10: 'seed = 122219, corte = 11105',\n",
    "                11: 'seed = 122219, corte = 11315',\n",
    "                12: 'seed = 122219, corte = 11526',\n",
    "                13: 'seed = 122219, corte = 11736',\n",
    "                14: 'seed = 122219, corte = 11947',\n",
    "                15: 'seed = 122219, corte = 12157',\n",
    "                16: 'seed = 122219, corte = 12368',\n",
    "                17: 'seed = 122219, corte = 12578',\n",
    "                18: 'seed = 122219, corte = 12789',\n",
    "                19: 'seed = 122219, corte = 13000',\n",
    "                20: 'seed = 109279, corte = 9000',\n",
    "                21: 'seed = 109279, corte = 9210',\n",
    "                22: 'seed = 109279, corte = 9421',\n",
    "                23: 'seed = 109279, corte = 9631',\n",
    "                24: 'seed = 109279, corte = 9842',\n",
    "                25: 'seed = 109279, corte = 10052',\n",
    "                26: 'seed = 109279, corte = 10263',\n",
    "                27: 'seed = 109279, corte = 10473',\n",
    "                28: 'seed = 109279, corte = 10684',\n",
    "                29: 'seed = 109279, corte = 10894',\n",
    "                30: 'seed = 109279, corte = 11105',\n",
    "                31: 'seed = 109279, corte = 11315',\n",
    "                32: 'seed = 109279, corte = 11526',\n",
    "                33: 'seed = 109279, corte = 11736',\n",
    "                34: 'seed = 109279, corte = 11947',\n",
    "                35: 'seed = 109279, corte = 12157',\n",
    "                36: 'seed = 109279, corte = 12368',\n",
    "                37: 'seed = 109279, corte = 12578',\n",
    "                38: 'seed = 109279, corte = 12789',\n",
    "                39: 'seed = 109279, corte = 13000',\n",
    "                40: 'seed = 400391, corte = 9000',\n",
    "                41: 'seed = 400391, corte = 9210',\n",
    "                42: 'seed = 400391, corte = 9421',\n",
    "                43: 'seed = 400391, corte = 9631',\n",
    "                44: 'seed = 400391, corte = 9842',\n",
    "                45: 'seed = 400391, corte = 10052',\n",
    "                46: 'seed = 400391, corte = 10263',\n",
    "                47: 'seed = 400391, corte = 10473',\n",
    "                48: 'seed = 400391, corte = 10684',\n",
    "                49: 'seed = 400391, corte = 10894',\n",
    "                50: 'seed = 400391, corte = 11105',\n",
    "                51: 'seed = 400391, corte = 11315',\n",
    "                52: 'seed = 400391, corte = 11526',\n",
    "                53: 'seed = 400391, corte = 11736',\n",
    "                54: 'seed = 400391, corte = 11947',\n",
    "                55: 'seed = 400391, corte = 12157',\n",
    "                56: 'seed = 400391, corte = 12368',\n",
    "                57: 'seed = 400391, corte = 12578',\n",
    "                58: 'seed = 400391, corte = 12789',\n",
    "                59: 'seed = 400391, corte = 13000',\n",
    "                60: 'seed = 401537, corte = 9000',\n",
    "                61: 'seed = 401537, corte = 9210',\n",
    "                62: 'seed = 401537, corte = 9421',\n",
    "                63: 'seed = 401537, corte = 9631',\n",
    "                64: 'seed = 401537, corte = 9842',\n",
    "                65: 'seed = 401537, corte = 10052',\n",
    "                66: 'seed = 401537, corte = 10263',\n",
    "                67: 'seed = 401537, corte = 10473',\n",
    "                68: 'seed = 401537, corte = 10684',\n",
    "                69: 'seed = 401537, corte = 10894',\n",
    "                70: 'seed = 401537, corte = 11105',\n",
    "                71: 'seed = 401537, corte = 11315',\n",
    "                72: 'seed = 401537, corte = 11526',\n",
    "                73: 'seed = 401537, corte = 11736',\n",
    "                74: 'seed = 401537, corte = 11947',\n",
    "                75: 'seed = 401537, corte = 12157',\n",
    "                76: 'seed = 401537, corte = 12368',\n",
    "                77: 'seed = 401537, corte = 12578',\n",
    "                78: 'seed = 401537, corte = 12789',\n",
    "                79: 'seed = 401537, corte = 13000',\n",
    "                80: 'seed = 999961, corte = 9000',\n",
    "                81: 'seed = 999961, corte = 9210',\n",
    "                82: 'seed = 999961, corte = 9421',\n",
    "                83: 'seed = 999961, corte = 9631',\n",
    "                84: 'seed = 999961, corte = 9842',\n",
    "                85: 'seed = 999961, corte = 10052',\n",
    "                86: 'seed = 999961, corte = 10263',\n",
    "                87: 'seed = 999961, corte = 10473',\n",
    "                88: 'seed = 999961, corte = 10684',\n",
    "                89: 'seed = 999961, corte = 10894',\n",
    "                90: 'seed = 999961, corte = 11105',\n",
    "                91: 'seed = 999961, corte = 11315',\n",
    "                92: 'seed = 999961, corte = 11526',\n",
    "                93: 'seed = 999961, corte = 11736',\n",
    "                94: 'seed = 999961, corte = 11947',\n",
    "                95: 'seed = 999961, corte = 12157',\n",
    "                96: 'seed = 999961, corte = 12368',\n",
    "                97: 'seed = 999961, corte = 12578',\n",
    "                98: 'seed = 999961, corte = 12789',\n",
    "                99: 'seed = 999961, corte = 13000'}\n",
    " })\n",
    "\n",
    "resultados['Public score'] = pd.to_numeric(resultados['Public score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'seed': np.repeat(semillas, len(puntos_corte)),\n",
    "    'corte': np.tile(puntos_corte, len(semillas))\n",
    "})\n",
    "\n",
    "resultados = pd.concat([resultados, df], axis=1)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.groupby('seed')['Public score'].agg(['min', 'max', 'mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = resultados.pivot(columns='seed', values='Public score')\n",
    "\n",
    "df_pivot.boxplot(figsize=(10, 6))\n",
    "plt.title('Boxplot of Public Score by Seed')\n",
    "plt.xlabel('Seed')\n",
    "plt.ylabel('Public Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: VIENDO LOS PRIVATE SCORES UNA VEZ QUE CERRO LA COMPETENCIA, LA SEMILLA 122219 QUE ES LA QUE POR LEJOS TUVO PEORES CREDIT SCORE, METIO LOS 15 MEJORES PRIVATE SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.groupby('corte')['Public score'].agg(['min', 'max', 'mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = resultados.pivot(columns='corte', values='Public score')\n",
    "\n",
    "df_pivot.boxplot(figsize=(10, 6))\n",
    "plt.title('Boxplot of Public Score by Seed')\n",
    "plt.xlabel('Corte')\n",
    "plt.ylabel('Public Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidatos:\n",
    "\n",
    "modelo original: seed = 122219, corte = 10669\n",
    "El punto de corte esta bien por lo que veo en el publico, pero la semilla es la que peor da de las 5,\n",
    "se que en el privado anduvo bien, sera porque quedaron los peores clasificados en el publico?\n",
    "\n",
    "alternativa: seed = 109279, corte = 11526\n",
    "es la mejor seed en el publico, pero capaz por esa misma razon es la peor en el privado?\n",
    "\n",
    "En validation da mejor el primer modelo, entonces capaz convenga elegirlo porque si le fue mal en el publico\n",
    "esperaria que en promedio le vaya mejor en el privado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data['foto_mes'] == 202103]\n",
    "test_data = data[data['foto_mes'] == 202104]\n",
    "\n",
    "X_train = train_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_train_binaria1 = train_data['clase_binaria1']\n",
    "y_train_binaria2 = train_data['clase_binaria2']\n",
    "w_train = train_data['clase_peso']\n",
    "\n",
    "X_test = test_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_test_binaria1 = test_data['clase_binaria1']\n",
    "y_test_class = test_data['clase_ternaria']\n",
    "w_test = test_data['clase_peso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train,\n",
    "                          label=y_train_binaria2,\n",
    "                          weight=w_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativa 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iter = 381 # cantidad de arboles del mejor modelo\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': 57,\n",
    "    'learning_rate': 0.02430667011066182,\n",
    "    'min_data_in_leaf': 741,\n",
    "    'feature_fraction': 0.43258351876617523,\n",
    "    'bagging_fraction': 0.4885097776912656,\n",
    "    'seed': 122219,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# y cantidad optima de envios segun backtesting\n",
    "corte = 10669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = lgb.train(params,\n",
    "                  train_data,\n",
    "                  num_boost_round=best_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = lgb.early_stopping(stopping_rounds=50) \n",
    "\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[early_stopping_cb],\n",
    "    feval=lgb_gan_eval,\n",
    "    stratified=True,\n",
    "    nfold=5,\n",
    "    seed=122219\n",
    ")\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "max_gan * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgm = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganancia = np.where(y_test_binaria1 == 1, ganancia_acierto, 0) - np.where(y_test_binaria1 == 0, costo_estimulo, 0)\n",
    "\n",
    "idx = np.argsort(y_pred_lgm)[::-1]\n",
    "\n",
    "ganancia = ganancia[idx]\n",
    "y_pred_lgm = y_pred_lgm[idx]\n",
    "\n",
    "ganancia_cum = np.cumsum(ganancia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piso_envios = 4000\n",
    "techo_envios = 20000\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_pred_lgm[piso_envios:techo_envios], ganancia_cum[piso_envios:techo_envios], label='Ganancia LGBM')\n",
    "plt.title('Curva de Ganancia')\n",
    "plt.xlabel('Predicción de probabilidad')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.axvline(x=0.025, color='g', linestyle='--', label='Punto de corte a 0.025')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piso_envios = 4000\n",
    "techo_envios = 20000\n",
    "\n",
    "ganancia_max = ganancia_cum.max()\n",
    "gan_max_idx = np.where(ganancia_cum == ganancia_max)[0][0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(piso_envios, len(ganancia_cum[piso_envios:techo_envios]) + piso_envios), ganancia_cum[piso_envios:techo_envios], label='Ganancia LGBM')\n",
    "plt.axvline(x=gan_max_idx, color='g', linestyle='--', label=f'Punto de corte a la ganancia máxima {gan_max_idx}')\n",
    "plt.axhline(y=ganancia_max, color='r', linestyle='--', label=f'Ganancia máxima {ganancia_max}')\n",
    "plt.title('Curva de Ganancia')\n",
    "plt.xlabel('Clientes')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativa 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iter = 381 # cantidad de arboles del mejor modelo\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': 57,\n",
    "    'learning_rate': 0.02430667011066182,\n",
    "    'min_data_in_leaf': 741,\n",
    "    'feature_fraction': 0.43258351876617523,\n",
    "    'bagging_fraction': 0.4885097776912656,\n",
    "    'seed': 109279,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# y cantidad optima de envios segun backtesting\n",
    "corte = 11526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = lgb.train(params,\n",
    "                  train_data,\n",
    "                  num_boost_round=best_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = lgb.early_stopping(stopping_rounds=50) \n",
    "\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[early_stopping_cb],\n",
    "    feval=lgb_gan_eval,\n",
    "    stratified=True,\n",
    "    nfold=5,\n",
    "    seed=109279\n",
    ")\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "max_gan * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgm = model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganancia = np.where(y_test_binaria1 == 1, ganancia_acierto, 0) - np.where(y_test_binaria1 == 0, costo_estimulo, 0)\n",
    "\n",
    "idx = np.argsort(y_pred_lgm)[::-1]\n",
    "\n",
    "ganancia = ganancia[idx]\n",
    "y_pred_lgm = y_pred_lgm[idx]\n",
    "\n",
    "ganancia_cum = np.cumsum(ganancia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piso_envios = 4000\n",
    "techo_envios = 20000\n",
    "\n",
    "ganancia_max = ganancia_cum.max()\n",
    "gan_max_idx = np.where(ganancia_cum == ganancia_max)[0][0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(piso_envios, len(ganancia_cum[piso_envios:techo_envios]) + piso_envios), ganancia_cum[piso_envios:techo_envios], label='Ganancia LGBM')\n",
    "plt.axvline(x=gan_max_idx, color='g', linestyle='--', label=f'Punto de corte a la ganancia máxima {gan_max_idx}')\n",
    "plt.axhline(y=ganancia_max, color='r', linestyle='--', label=f'Ganancia máxima {ganancia_max}')\n",
    "plt.title('Curva de Ganancia')\n",
    "plt.xlabel('Clientes')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=1000, # modificar, subit y subir... y descomentar la línea inferior (ahora le puso 100 para mostrarnos, pero hay que ponerle un numero alto, 10.000, 200.000)\n",
    "    # early_stopping_rounds= int((50 + 5) / learning_rate), # (ale dijo que lo mas comun es que sea 1/learning rate)\n",
    "    # early_stopping_rounds = 50,\n",
    "    callbacks=[early_stopping_cb],\n",
    "    feval=lgb_gan_eval,\n",
    "    stratified=True,\n",
    "    nfold=5,\n",
    "    seed=semillas[0]\n",
    ")\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "# Guardamos cual es la mejor iteración del modelo\n",
    "trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "return max_gan * 5"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
