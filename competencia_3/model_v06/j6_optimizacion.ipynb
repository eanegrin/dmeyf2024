{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Cj-rL6xHlA2u"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/eanegrin/buckets/b1/datasets/competencia_03_fe_v06_undersampled.parquet...\n",
      "- [1 files][552.0 MiB/552.0 MiB]                                                \n",
      "Operation completed over 1 objects/552.0 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp /home/eanegrin/buckets/b1/datasets/competencia_03_fe_v06_undersampled.parquet /home/eanegrin/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8jGKjoN1lRho"
   },
   "outputs": [],
   "source": [
    "# base_path = 'C:/Eugenio/Maestria/DMEyF/'\n",
    "base_path = '/home/eanegrin/buckets/b1/'\n",
    "\n",
    "dataset_path = base_path + 'datasets/'\n",
    "modelos_path = base_path + 'modelos/'\n",
    "db_path = base_path + 'db/'\n",
    "dataset_file = 'competencia_03_fe_v06_undersampled.parquet'\n",
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "semillas = [122219, 109279, 400391, 401537, 999961]\n",
    "\n",
    "data = pd.read_parquet('/home/eanegrin/datasets/' + dataset_file)\n",
    "# data = pd.read_parquet(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([202007, 202008, 202009, 202010, 202011, 202012, 202101, 202102,\n",
       "       202103, 202104, 202105, 202106])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# el dataset undersampleado ya excluye los meses \"malos\" y los que tienen la clase ternaria incompleta\n",
    "# nos queda excluir el mes de testing:\n",
    "\n",
    "data = data[data['foto_mes'] != 202107]\n",
    "\n",
    "data['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211679, 1152)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos pesos a las clases\n",
    "\n",
    "data['clase_peso'] = 1.0\n",
    "\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria'], axis=1)\n",
    "y_train_binaria = data['clase_binaria']\n",
    "w_train = data['clase_peso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar la calidad del modelo, crearemos nuestra propia función de evaluación que calcule la ganancia. La razón de incluir los pesos es precisamente para poder implementar esta función de evaluación de manera adecuada. Al combinar las clases *BAJA+1* y *BAJA+2* en una sola, necesitamos una forma de diferenciarlas, y es aquí donde entra en juego el *weight*. Este parámetro nos permitirá distinguir entre ambas clases al momento de evaluarlas dentro del algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 200),\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.05),\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 64, 2000),\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': semillas[1],\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                              label=y_train_binaria,\n",
    "                              weight=w_train)\n",
    "    \n",
    "    # print(f\"Learning Rate: {learning_rate}, Type: {type(learning_rate)}\")\n",
    "    \n",
    "    # callbacks for early stopping\n",
    "    early_stopping_cb = lgb.early_stopping(stopping_rounds=200)\n",
    "        \n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=2000,\n",
    "        callbacks=[early_stopping_cb],\n",
    "        feval=lgb_gan_eval,\n",
    "        stratified=True,\n",
    "        nfold=5,\n",
    "        seed=semillas[1]\n",
    "    )\n",
    "    \n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 5 # funcion objetivo, en el proximo paso le digo si quiero maximizarla o minimizarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYMEnNFbkSoQ",
    "outputId": "15d768d4-9e25-4063-984b-d79c90ea91bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-04 03:17:36,218] A new study created in RDB with name: competencia3_lgbm_v06\n"
     ]
    }
   ],
   "source": [
    "storage_name = \"sqlite:///\" + db_path + \"optimization_lgbm.db\"\n",
    "study_name = \"competencia3_lgbm_v06\" # UPDATE\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMrT22K0u9JF",
    "outputId": "75ee1c52-fb2c-4ad4-df1e-1d0852a3867e"
   },
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ia2vN07FEasX"
   },
   "source": [
    "Analizamos los resultados as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "fH4ybQgYx7Xf",
    "outputId": "e2492e33-7da9-408e-bc68-ecc14c0fdf99"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "vOfm5DXAx8Rj",
    "outputId": "7ea05841-331e-48cb-fcb9-c36e97ab2051"
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "0U6CfznSx-gG",
    "outputId": "f3c4a028-2d47-4e6e-ba8b-2877fe9d843a"
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "XRqPgCD6yB_q",
    "outputId": "0adae389-2981-43ee-c939-212232dd4f31"
   },
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "wGHGdGcQ3m00",
    "outputId": "624ee6d0-a5f1-4b00-bac6-8f37de7e99a7"
   },
   "outputs": [],
   "source": [
    "plot_contour(study, params=['num_leaves','min_data_in_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "best_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
