{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp /home/eanegrin/buckets/b1/datasets/competencia_02_fe_v01.parquet /home/eanegrin/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'C:/Eugenio/Maestria/DMEyF/'\n",
    "# base_path = '/home/eanegrin/buckets/b1/'\n",
    "\n",
    "dataset_path = base_path + 'datasets/'\n",
    "modelos_path = base_path + 'modelos/'\n",
    "db_path = base_path + 'db/'\n",
    "dataset_file = 'competencia_03_fe_v08_undersampled.parquet'\n",
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "semillas = [1149, 4836, 9443, 7483, 3492, 6287, 830, 3294, 5932, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_parquet('/home/eanegrin/datasets/' + dataset_file)\n",
    "data = pd.read_parquet(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_peso'] = 1.0\n",
    "\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_binaria'] = 0\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria'] == 'CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria'], axis=1)\n",
    "y_train_binaria = data['clase_binaria']\n",
    "w_train = data['clase_peso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 09:50:20,710] Using an existing study with name 'competencia3_lgbm_v08' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "storage_name = \"sqlite:///\" + db_path + \"optimization_lgbm_v08.db\"\n",
    "study_name = \"competencia3_lgbm_v08\" # UPDATE\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = study.trials_dataframe()\n",
    "resultados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 248,\n",
       " 'learning_rate': 0.0498907204475266,\n",
       " 'min_data_in_leaf': 121,\n",
       " 'feature_fraction': 0.42739407657827894,\n",
       " 'bagging_fraction': 0.4653942981227891}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reentrenamos los modelos individuales con la totalidad de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor cantidad de árboles para el mejor model 1909\n",
      "1. Train del modelo v008 con semilla 1149\n",
      "2. Train del modelo v008 con semilla 4836\n",
      "3. Train del modelo v008 con semilla 9443\n",
      "4. Train del modelo v008 con semilla 7483\n",
      "5. Train del modelo v008 con semilla 3492\n",
      "6. Train del modelo v008 con semilla 6287\n",
      "7. Train del modelo v008 con semilla 830\n",
      "8. Train del modelo v008 con semilla 3294\n",
      "9. Train del modelo v008 con semilla 5932\n",
      "10. Train del modelo v008 con semilla 13\n"
     ]
    }
   ],
   "source": [
    "version = 'v008' # UPDATE\n",
    "\n",
    "os.makedirs(modelos_path + 'v010', exist_ok= True) # carpeta donde vamos a almacenar los modelos que va a usar el ensamble\n",
    "\n",
    "best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for semilla in semillas:\n",
    "    \n",
    "    counter += 1\n",
    "    print(f'{counter}. Train del modelo {version} con semilla {semilla}')    \n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': study.best_trial.params['num_leaves'],\n",
    "        'learning_rate': study.best_trial.params['learning_rate'],\n",
    "        'min_data_in_leaf': study.best_trial.params['min_data_in_leaf'],\n",
    "        'feature_fraction': study.best_trial.params['feature_fraction'],\n",
    "        'bagging_fraction': study.best_trial.params['bagging_fraction'],\n",
    "        'seed': semilla,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                            label=y_train_binaria,\n",
    "                            weight=w_train)\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=best_iter)\n",
    "    \n",
    "    model.save_model(modelos_path + f'v010/lgb_competencia3_{version}_s{semilla}_final.txt') # _final para indicar que es la version entrenada con todo el conjunto disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
