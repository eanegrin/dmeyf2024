{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Cj-rL6xHlA2u"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp /home/eanegrin/buckets/b1/datasets/competencia_02_fe_v01.parquet /home/eanegrin/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8jGKjoN1lRho"
   },
   "outputs": [],
   "source": [
    "# base_path = '/content/drive/MyDrive/DMEyF/2024/'\n",
    "base_path = 'C:/Eugenio/Maestria/DMEyF/'\n",
    "# base_path = '/home/eanegrin/buckets/b1/'\n",
    "\n",
    "dataset_path = base_path + 'datasets/'\n",
    "modelos_path = base_path + 'modelos/'\n",
    "db_path = base_path + 'db/'\n",
    "dataset_file = 'competencia_02_inflacion_adj_cpe.parquet'\n",
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "# data = pd.read_parquet('/home/eanegrin/datasets/' + dataset_file)\n",
    "data = pd.read_parquet(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrijo los tipos de estas 2 columnas que se guardaron como string en el parquet\n",
    "\n",
    "data[['tmobile_app', 'cmobile_app_trx']] = data[['tmobile_app', 'cmobile_app_trx']].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3608481, 155)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meses_train = [201906, 201907, 201908, 201909, 201910, 201911, 201912,\n",
    "               202001, 202002, 202003, 202004, 202005, 202006,\n",
    "               202007, 202008, 202009, 202010, 202011, 202012,\n",
    "               202101, 202102, 202103, 202104, 202105] # dejo afuera 202106 para test\n",
    "\n",
    "data = data[data['foto_mes'].isin(meses_train)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos pesos a las clases\n",
    "\n",
    "data['clase_peso'] = 1.0\n",
    "\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_binaria'] = 0\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria'] == 'CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria'], axis=1)\n",
    "y_train_binaria = data['clase_binaria'] # Junta a los 2 baja\n",
    "w_train = data['clase_peso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar la calidad del modelo, crearemos nuestra propia función de evaluación que calcule la ganancia. La razón de incluir los pesos es precisamente para poder implementar esta función de evaluación de manera adecuada. Al combinar las clases *BAJA+1* y *BAJA+2* en una sola, necesitamos una forma de diferenciarlas, y es aquí donde entra en juego el *weight*. Este parámetro nos permitirá distinguir entre ambas clases al momento de evaluarlas dentro del algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el study de optuna que optimizamos en el script anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYMEnNFbkSoQ",
    "outputId": "15d768d4-9e25-4063-984b-d79c90ea91bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-19 20:30:01,541] Using an existing study with name 'experimento_cpe_v01' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "storage_name = \"sqlite:///\" + db_path + \"optimization_experimento_cpe.db\"\n",
    "study_name = \"experimento_cpe_v01\" # UPDATE\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = study.trials_dataframe()\n",
    "resultados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos con 20 semillas y guardamos los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n",
      "Mejor cantidad de árboles para el mejor model 997\n"
     ]
    }
   ],
   "source": [
    "version = 'cpe_v01' # UPDATE\n",
    "\n",
    "semillas = [779, 296, 720, 433, 405, 610, 902, 910, 535, 734, 325, 469, 841, 399, 929, 481, 521, 709, 444, 596]\n",
    "\n",
    "for semilla in semillas:\n",
    "    \n",
    "    best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "    print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': study.best_trial.params['num_leaves'],\n",
    "        'learning_rate': study.best_trial.params['learning_rate'],\n",
    "        'min_data_in_leaf': study.best_trial.params['min_data_in_leaf'],\n",
    "        'feature_fraction': study.best_trial.params['feature_fraction'],\n",
    "        'bagging_fraction': study.best_trial.params['bagging_fraction'],\n",
    "        'seed': semilla,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                            label=y_train_binaria,\n",
    "                            weight=w_train)\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=best_iter)\n",
    "    \n",
    "    model.save_model(modelos_path + f'experimento/lgb_experimento_{version}_s{semilla}.txt')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
